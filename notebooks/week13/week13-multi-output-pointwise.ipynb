{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate, train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T19:02:06.424160500Z",
     "start_time": "2023-07-20T19:02:06.408637400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import src.evaluate_regression as er\n",
    "import src.load_datasets as ld\n",
    "\n",
    "from src.encoding import ohe_encode_train_data\n",
    "from src.meta_information import add_dataset_meta_information\n",
    "from src.feature_engineering import normalize_train_data\n",
    "from src.data_cleaning import drop_pearson_correlated_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:31.551722200Z",
     "start_time": "2023-07-20T18:26:31.531373400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\") # Paired"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:31.711882200Z",
     "start_time": "2023-07-20T18:26:31.681727200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "random_state = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:31.912496400Z",
     "start_time": "2023-07-20T18:26:31.881325400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:32.251626300Z",
     "start_time": "2023-07-20T18:26:32.231549700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from '../../data/raw/dataset_rank_train.csv' ...\n"
     ]
    }
   ],
   "source": [
    "df_train = ld.load_dataset(\"../../data/raw/dataset_rank_train.csv\")\n",
    "if \"cv_score\" in df_train.columns:\n",
    "    df_train = df_train.drop(\"cv_score\", axis=1)\n",
    "df_train, df_holdout = train_test_split(df_train, test_size=0.2, random_state=random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:32.514210800Z",
     "start_time": "2023-07-20T18:26:32.426366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (28843, 6)\n",
      "Columns of train data:  Index(['dataset', 'model', 'tuning', 'scoring', 'encoder', 'rank'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "       dataset model tuning scoring      encoder  rank\n21436    43922    LR   full      F1           SE   1.0\n7324     42738   DTC  model     ACC  BUCV2RGLMME  26.0\n14725       31    LR  model     ACC        ME01E  11.0\n30041    43922    LR     no      F1         WOEE   0.0\n644         56    LR  model     AUC        DTEM2   1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>tuning</th>\n      <th>scoring</th>\n      <th>encoder</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21436</th>\n      <td>43922</td>\n      <td>LR</td>\n      <td>full</td>\n      <td>F1</td>\n      <td>SE</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7324</th>\n      <td>42738</td>\n      <td>DTC</td>\n      <td>model</td>\n      <td>ACC</td>\n      <td>BUCV2RGLMME</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>14725</th>\n      <td>31</td>\n      <td>LR</td>\n      <td>model</td>\n      <td>ACC</td>\n      <td>ME01E</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>30041</th>\n      <td>43922</td>\n      <td>LR</td>\n      <td>no</td>\n      <td>F1</td>\n      <td>WOEE</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>56</td>\n      <td>LR</td>\n      <td>model</td>\n      <td>AUC</td>\n      <td>DTEM2</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of train data: \", df_train.shape)\n",
    "print(\"Columns of train data: \", df_train.columns)\n",
    "#df_train.sort_values(by=[\"dataset\", \"rank\"], inplace=True)\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:32.704113500Z",
     "start_time": "2023-07-20T18:26:32.661387900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pivot data to get multi-output target of encoder ranking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# statics of rank\n",
    "factors = [\"dataset\", \"model\", \"tuning\", \"scoring\"]\n",
    "new_index = \"encoder\"\n",
    "target = \"rank\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:33.021416500Z",
     "start_time": "2023-07-20T18:26:33.001342800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "# pivot encoder column with rank as value\n",
    "df_train_pivot = df_train.pivot_table(\n",
    "    index=factors, columns=new_index, values=target, aggfunc=\"first\"\n",
    ").reset_index()\n",
    "df_holdout_pivot = df_holdout.pivot_table(\n",
    "    index=factors, columns=new_index, values=target, aggfunc=\"first\"\n",
    ").reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:33.263948600Z",
     "start_time": "2023-07-20T18:26:33.196546500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (1160, 36)\n",
      "Columns of train data:  Index(['dataset', 'model', 'tuning', 'scoring', 'BE', 'BUCV10RGLMME',\n",
      "       'BUCV10TE', 'BUCV2RGLMME', 'BUCV2TE', 'BUCV5RGLMME', 'BUCV5TE', 'CBE',\n",
      "       'CE', 'CV10RGLMME', 'CV10TE', 'CV2RGLMME', 'CV2TE', 'CV5RGLMME',\n",
      "       'CV5TE', 'DE', 'DTEM10', 'DTEM2', 'DTEM5', 'ME01E', 'ME10E', 'ME1E',\n",
      "       'MHE', 'OE', 'OHE', 'PBTE0001', 'PBTE001', 'PBTE01', 'RGLMME', 'SE',\n",
      "       'TE', 'WOEE'],\n",
      "      dtype='object', name='encoder')\n"
     ]
    },
    {
     "data": {
      "text/plain": "encoder  dataset model tuning scoring    BE  BUCV10RGLMME  BUCV10TE  \\\n0              3   DTC   full     ACC   NaN           1.0       1.0   \n1              3   DTC   full     AUC   1.0           NaN       1.0   \n2              3   DTC   full      F1   1.0           NaN       1.0   \n3              3   DTC  model     AUC  12.0          14.0       0.0   \n4              3   DTC  model      F1  12.0          13.0       0.0   \n\nencoder  BUCV2RGLMME  BUCV2TE  BUCV5RGLMME  ...  MHE   OE  OHE  PBTE0001  \\\n0                1.0      1.0          1.0  ...  1.0  1.0  1.0       NaN   \n1                1.0      1.0          1.0  ...  1.0  1.0  1.0       1.0   \n2                1.0      1.0          1.0  ...  1.0  1.0  1.0       1.0   \n3               18.0      NaN         17.0  ...  2.0  9.0  5.0       7.0   \n4               18.0      6.0          NaN  ...  2.0  9.0  5.0       NaN   \n\nencoder  PBTE001  PBTE01  RGLMME   SE   TE  WOEE  \n0            1.0     2.0     1.0  NaN  1.0   1.0  \n1            1.0     2.0     1.0  1.0  1.0   1.0  \n2            1.0     2.0     1.0  1.0  1.0   1.0  \n3            NaN    23.0    19.0  1.0  3.0   3.0  \n4           11.0    23.0    19.0  1.0  3.0   NaN  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>encoder</th>\n      <th>dataset</th>\n      <th>model</th>\n      <th>tuning</th>\n      <th>scoring</th>\n      <th>BE</th>\n      <th>BUCV10RGLMME</th>\n      <th>BUCV10TE</th>\n      <th>BUCV2RGLMME</th>\n      <th>BUCV2TE</th>\n      <th>BUCV5RGLMME</th>\n      <th>...</th>\n      <th>MHE</th>\n      <th>OE</th>\n      <th>OHE</th>\n      <th>PBTE0001</th>\n      <th>PBTE001</th>\n      <th>PBTE01</th>\n      <th>RGLMME</th>\n      <th>SE</th>\n      <th>TE</th>\n      <th>WOEE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>DTC</td>\n      <td>full</td>\n      <td>ACC</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>DTC</td>\n      <td>full</td>\n      <td>AUC</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>DTC</td>\n      <td>full</td>\n      <td>F1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>DTC</td>\n      <td>model</td>\n      <td>AUC</td>\n      <td>12.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>19.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>DTC</td>\n      <td>model</td>\n      <td>F1</td>\n      <td>12.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>23.0</td>\n      <td>19.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of train data: \", df_train_pivot.shape)\n",
    "print(\"Columns of train data: \", df_train_pivot.columns)\n",
    "df_train_pivot.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:33.487247200Z",
     "start_time": "2023-07-20T18:26:33.381347900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# Set train variables\n",
    "X_train = df_train_pivot[factors]\n",
    "y_train = df_train_pivot.drop(factors, axis=1)\n",
    "# Set holdout variables\n",
    "X_holdout = df_holdout_pivot[factors]\n",
    "y_holdout = df_holdout_pivot.drop(factors, axis=1)\n",
    "# Update target\n",
    "target = y_train.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:33.707359700Z",
     "start_time": "2023-07-20T18:26:33.631534800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train data:  0\n",
      "Missing values in target:  8277\n",
      "Missing values in holdout data:  0\n",
      "Missing values in holdout target:  29813\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in train data: \", X_train.isnull().sum().sum())\n",
    "print(\"Missing values in target: \", y_train.isnull().sum().sum())\n",
    "print(\"Missing values in holdout data: \", X_holdout.isnull().sum().sum())\n",
    "print(\"Missing values in holdout target: \", y_holdout.isnull().sum().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:33.855429400Z",
     "start_time": "2023-07-20T18:26:33.823593200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "# Fill missing values (or np.max() of target)\n",
    "y_train.fillna(y_train.median(), inplace=True)\n",
    "y_holdout.fillna(y_train.median(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:34.891343100Z",
     "start_time": "2023-07-20T18:26:34.841689400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train data:  0\n",
      "Missing values in target:  0\n",
      "Missing values in holdout data:  0\n",
      "Missing values in holdout target:  0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in train data: \", X_train.isnull().sum().sum())\n",
    "print(\"Missing values in target: \", y_train.isnull().sum().sum())\n",
    "print(\"Missing values in holdout data: \", X_holdout.isnull().sum().sum())\n",
    "print(\"Missing values in holdout target: \", y_holdout.isnull().sum().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:35.264601100Z",
     "start_time": "2023-07-20T18:26:35.221435700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "# Save copy of unprocessed train data\n",
    "X_train_original = X_train.copy()\n",
    "X_holdout_original = X_holdout.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:37.871683500Z",
     "start_time": "2023-07-20T18:26:37.841644500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoding the features ['model', 'tuning', 'scoring'] of the train data ...\n",
      "One Hot Encoding the features ['model', 'tuning', 'scoring'] of the train data ...\n",
      "Drop pearson correlated features with threshold 0.7...\n",
      "Filter correlated features\n",
      "Drop pearson correlated features with threshold 0.7...\n",
      "Filter correlated features\n",
      "Normalizing train data using method 'minmax' ...\n",
      "Normalizing train data using method 'minmax' ...\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 606 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encode categorical features\n",
    "X_train, _ = ohe_encode_train_data(X_train=X_train, cols_to_encode=[\"model\", \"tuning\", \"scoring\"], verbosity=1)\n",
    "X_holdout, _ = ohe_encode_train_data(X_train=X_holdout, cols_to_encode=[\"model\", \"tuning\", \"scoring\"], verbosity=1)\n",
    "# Add meta information\n",
    "X_train = add_dataset_meta_information(df=X_train,\n",
    "                                        path_to_meta_df=\"../../data/preprocessed/dataset_agg.csv\",\n",
    "                                        nan_threshold=0.5,\n",
    "                                        replacing_strategy=\"median\")\n",
    "X_holdout = add_dataset_meta_information(df=X_holdout,\n",
    "                                        path_to_meta_df=\"../../data/preprocessed/dataset_agg.csv\",\n",
    "                                        nan_threshold=0.5,\n",
    "                                        replacing_strategy=\"median\")\n",
    "# Drop correlated features\n",
    "X_train, _ = drop_pearson_correlated_features(train_data=X_train, test_data=None, threshold=0.7, verbosity=1)\n",
    "X_holdout, _ = drop_pearson_correlated_features(train_data=X_holdout, test_data=None, threshold=0.7, verbosity=1)\n",
    "# Normalize\n",
    "X_train, scaler = normalize_train_data(X_train=X_train, method=\"minmax\", verbosity=1)\n",
    "X_holdout, _ = normalize_train_data(X_train=X_holdout, method=\"minmax\", verbosity=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:43.661365500Z",
     "start_time": "2023-07-20T18:26:43.051762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (1160, 40)\n",
      "Columns of train data:  Index(['dataset', 'model_DTC', 'model_KNC', 'model_LGBMC', 'model_LR',\n",
      "       'model_SVC', 'tuning_full', 'tuning_model', 'tuning_no', 'scoring_ACC',\n",
      "       'scoring_AUC', 'scoring_F1', 'Quartile1KurtosisOfNumericAtts',\n",
      "       'J48.001.ErrRate', 'Dimensionality', 'Quartile2MutualInformation',\n",
      "       'MinSkewnessOfNumericAtts', 'Quartile2AttributeEntropy',\n",
      "       'MinorityClassSize', 'MajorityClassPercentage',\n",
      "       'Quartile2StdDevOfNumericAtts', 'NumberOfBinaryFeatures',\n",
      "       'Quartile1MutualInformation', 'Quartile1MeansOfNumericAtts',\n",
      "       'MaxMutualInformation', 'AutoCorrelation', 'PercentageOfBinaryFeatures',\n",
      "       'MinKurtosisOfNumericAtts', 'DecisionStumpErrRate',\n",
      "       'PercentageOfNumericFeatures', 'NumberOfSymbolicFeatures',\n",
      "       'MinMutualInformation', 'PercentageOfInstancesWithMissingValues',\n",
      "       'MinNominalAttDistinctValues', 'NumberOfNumericFeatures',\n",
      "       'rows_with_null_values_count', 'categorical_target_variables_count',\n",
      "       'non_categorical_target_variables_count',\n",
      "       'categorical_target_values_sum',\n",
      "       'min_number_of_categories_per_cat_feature'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "   dataset  model_DTC  model_KNC  model_LGBMC  model_LR  model_SVC  \\\n0      0.0        1.0        0.0          0.0       0.0        0.0   \n1      0.0        1.0        0.0          0.0       0.0        0.0   \n2      0.0        1.0        0.0          0.0       0.0        0.0   \n3      0.0        1.0        0.0          0.0       0.0        0.0   \n4      0.0        1.0        0.0          0.0       0.0        0.0   \n\n   tuning_full  tuning_model  tuning_no  scoring_ACC  ...  \\\n0          1.0           0.0        0.0          1.0  ...   \n1          1.0           0.0        0.0          0.0  ...   \n2          1.0           0.0        0.0          0.0  ...   \n3          0.0           1.0        0.0          0.0  ...   \n4          0.0           1.0        0.0          0.0  ...   \n\n   NumberOfSymbolicFeatures  MinMutualInformation  \\\n0                  0.270073          4.793819e-08   \n1                  0.270073          4.793819e-08   \n2                  0.270073          4.793819e-08   \n3                  0.270073          4.793819e-08   \n4                  0.270073          4.793819e-08   \n\n   PercentageOfInstancesWithMissingValues  MinNominalAttDistinctValues  \\\n0                                     0.0                          1.0   \n1                                     0.0                          1.0   \n2                                     0.0                          1.0   \n3                                     0.0                          1.0   \n4                                     0.0                          1.0   \n\n   NumberOfNumericFeatures  rows_with_null_values_count  \\\n0                      0.0                          0.0   \n1                      0.0                          0.0   \n2                      0.0                          0.0   \n3                      0.0                          0.0   \n4                      0.0                          0.0   \n\n   categorical_target_variables_count  non_categorical_target_variables_count  \\\n0                                 0.0                                     0.0   \n1                                 0.0                                     0.0   \n2                                 0.0                                     0.0   \n3                                 0.0                                     0.0   \n4                                 0.0                                     0.0   \n\n   categorical_target_values_sum  min_number_of_categories_per_cat_feature  \n0                            0.0                                  0.015152  \n1                            0.0                                  0.015152  \n2                            0.0                                  0.015152  \n3                            0.0                                  0.015152  \n4                            0.0                                  0.015152  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>model_DTC</th>\n      <th>model_KNC</th>\n      <th>model_LGBMC</th>\n      <th>model_LR</th>\n      <th>model_SVC</th>\n      <th>tuning_full</th>\n      <th>tuning_model</th>\n      <th>tuning_no</th>\n      <th>scoring_ACC</th>\n      <th>...</th>\n      <th>NumberOfSymbolicFeatures</th>\n      <th>MinMutualInformation</th>\n      <th>PercentageOfInstancesWithMissingValues</th>\n      <th>MinNominalAttDistinctValues</th>\n      <th>NumberOfNumericFeatures</th>\n      <th>rows_with_null_values_count</th>\n      <th>categorical_target_variables_count</th>\n      <th>non_categorical_target_variables_count</th>\n      <th>categorical_target_values_sum</th>\n      <th>min_number_of_categories_per_cat_feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.270073</td>\n      <td>4.793819e-08</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.270073</td>\n      <td>4.793819e-08</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015152</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.270073</td>\n      <td>4.793819e-08</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015152</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.270073</td>\n      <td>4.793819e-08</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015152</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.270073</td>\n      <td>4.793819e-08</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015152</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of train data: \", X_train.shape)\n",
    "print(\"Columns of train data: \", X_train.columns)\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:26:43.938546100Z",
     "start_time": "2023-07-20T18:26:43.843577300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Evaluate models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "# Model selection for multi-class classification\n",
    "models = {\n",
    "    \"Random Forest\": MultiOutputRegressor(RandomForestRegressor(random_state=random_state)),\n",
    "    \"XGBoost\": MultiOutputRegressor(XGBRegressor(random_state=random_state)),\n",
    "    \"LightGBM\": MultiOutputRegressor(LGBMRegressor(random_state=random_state)),\n",
    "    \"KNN\": MultiOutputRegressor(KNeighborsRegressor()),\n",
    "    \"CatBoost\": MultiOutputRegressor(CatBoostRegressor(random_state=random_state, silent=True)),\n",
    "    \"Decision Tree\": MultiOutputRegressor(DecisionTreeRegressor(random_state=random_state)),\n",
    "    \"Gradient Boosting\": MultiOutputRegressor(GradientBoostingRegressor(random_state=random_state)),\n",
    "    # Add other multi-output regression models here if needed\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T19:02:12.540372900Z",
     "start_time": "2023-07-20T19:02:12.524490Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## via cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "# Get indices of train data\n",
    "cv_indices = er.custom_cross_validated_indices(pd.concat([X_train_original, y_train], axis=1), factors, target, n_splits=5, shuffle=True, random_state=random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T18:49:31.328067300Z",
     "start_time": "2023-07-20T18:49:31.265065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "# Define scoring for CV\n",
    "scoring = {\n",
    "    'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    'r2': make_scorer(r2_score)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T19:09:53.225965700Z",
     "start_time": "2023-07-20T19:09:53.202041500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  Random Forest\n",
      "\n",
      "CV Training neg_mean_squared_error: -3.9901 +/- 0.042 \n",
      "CV Test neg_mean_squared_error: -28.6935 +/- 0.8862\n",
      "CV Training r2: 0.9245 +/- 0.0006 \n",
      "CV Test r2: 0.4524 +/- 0.0103\n",
      "\n",
      "Training model:  XGBoost\n",
      "\n",
      "CV Training neg_mean_squared_error: -0.6032 +/- 0.0116 \n",
      "CV Test neg_mean_squared_error: -33.4201 +/- 0.9938\n",
      "CV Training r2: 0.9886 +/- 0.0002 \n",
      "CV Test r2: 0.3603 +/- 0.0104\n",
      "\n",
      "Training model:  LightGBM\n",
      "\n",
      "CV Training neg_mean_squared_error: -9.7467 +/- 0.097 \n",
      "CV Test neg_mean_squared_error: -29.9793 +/- 0.9563\n",
      "CV Training r2: 0.8154 +/- 0.0017 \n",
      "CV Test r2: 0.4283 +/- 0.0127\n",
      "\n",
      "Training model:  KNN\n",
      "\n",
      "CV Training neg_mean_squared_error: -36.6004 +/- 0.2284 \n",
      "CV Test neg_mean_squared_error: -54.5189 +/- 0.6054\n",
      "CV Training r2: 0.3132 +/- 0.0041 \n",
      "CV Test r2: -0.0312 +/- 0.0203\n",
      "\n",
      "Training model:  CatBoost\n",
      "\n",
      "CV Training neg_mean_squared_error: -3.7631 +/- 0.0147 \n",
      "CV Test neg_mean_squared_error: -29.4076 +/- 0.8775\n",
      "CV Training r2: 0.9289 +/- 0.0002 \n",
      "CV Test r2: 0.4375 +/- 0.0122\n",
      "\n",
      "Training model:  Decision Tree\n",
      "\n",
      "CV Training neg_mean_squared_error: 0.0 +/- 0.0 \n",
      "CV Test neg_mean_squared_error: -52.0366 +/- 2.0673\n",
      "CV Training r2: 1.0 +/- 0.0 \n",
      "CV Test r2: 0.0042 +/- 0.026\n",
      "\n",
      "Training model:  Gradient Boosting\n",
      "\n",
      "CV Training neg_mean_squared_error: -22.8862 +/- 0.2149 \n",
      "CV Test neg_mean_squared_error: -32.5127 +/- 1.1104\n",
      "CV Training r2: 0.5681 +/- 0.0032 \n",
      "CV Test r2: 0.3812 +/- 0.0157\n",
      "\n",
      "CPU times: total: 11min 35s\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train and evaluate models\n",
    "cv_results = []\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    print(\"Training model: \", model_name, f\"({i+1}/{len(models)})\", \"...\")\n",
    "\n",
    "    # MinMax scale target if necessary (for ExtraTreesRegressor)\n",
    "    if model_name == \"ExtraTrees\":\n",
    "        scaler = MinMaxScaler()\n",
    "        y_scaled = scaler.fit_transform(y_train)\n",
    "        y_train = pd.DataFrame(y_scaled, columns=y_train.columns)\n",
    "\n",
    "    # Perform CV\n",
    "    results = cross_validate(estimator=model, X=X_train, y=y_train, cv=cv_indices, scoring=scoring, return_train_score=True, error_score=\"raise\")\n",
    "    cv_results.append(results)\n",
    "\n",
    "    # Iterate through the provided scoring (list) in cv_results and print results\n",
    "    for scorer in scoring:\n",
    "        print(f\"CV Training {scorer}: {round(results['train_' + scorer].mean(), 4)} \"\n",
    "              f\"+/- {round(results['train_' + scorer].std(), 4)} \")\n",
    "        print(f\"CV Test {scorer}: {round(results['test_' + scorer].mean(), 4)} \"\n",
    "                f\"+/- {round(results['test_' + scorer].std(), 4)}\")\n",
    "    print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T19:25:36.393662500Z",
     "start_time": "2023-07-20T19:18:12.586663200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## via custom average spearmen on holdout set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  Random Forest (1/7) ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train and evaluate models\n",
    "holdout_results = []\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    print(\"Training model: \", model_name, f\"({i+1}/{len(models)})\", \"...\")\n",
    "\n",
    "    # MinMax scale target if necessary (for ExtraTreesRegressor)\n",
    "    if model_name == \"ExtraTrees\":\n",
    "        scaler = MinMaxScaler()\n",
    "        y_scaled = scaler.fit_transform(y_train)\n",
    "        y_train = pd.DataFrame(y_scaled, columns=y_train.columns)\n",
    "\n",
    "    # Train model on train set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on holdout set\n",
    "    y_holdout_pred = pd.DataFrame(model.predict(X_holdout), columns=y_holdout.columns, index=X_holdout.index)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    df_pred = pd.merge(pd.concat([X_holdout_original, y_holdout], axis=1).melt(id_vars=factors, value_name=\"rank\").dropna(axis=0),\n",
    "                       pd.concat([X_holdout_original, y_holdout_pred], axis=1).melt(id_vars=factors, value_name=\"pred_rank\").dropna(axis=0),\n",
    "                       on=factors+\"encoder\", how=\"left\")\n",
    "    print(test)\n",
    "\n",
    "    # Get rankings\n",
    "    rankings_holdout = er.get_rankings(df=df_pred, factors=factors, target=\"rank\")\n",
    "    rankings_holdout_pred = er.get_rankings(df=df_pred, factors=factors, target=\"pred_rank\")\n",
    "\n",
    "    # Custom average spearman\n",
    "    spearman = er.custom_average_spearman(rankings_holdout, rankings_holdout_pred)\n",
    "    holdout_results.append(spearman)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average Spearman: {round(spearman, 4)}\")\n",
    "    print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-20T20:42:06.608770700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## compare results in plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cv_results = pd.DataFrame(cv_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_holdout_results = pd.DataFrame(holdout_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
