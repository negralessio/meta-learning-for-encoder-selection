{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8975adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eacf5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b22678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from src.load_datasets import load_dataset, load_rankings, load_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4204db",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb080cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading rankings ...\n",
      "Loading train data ...\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('../../data/raw/dataset.csv')\n",
    "rankings = load_rankings('../../data/raw/rankings.csv')\n",
    "X_train, y_train = load_train_data('../../data/raw/dataset_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba05d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_encoders = dataset.encoder.unique()\n",
    "unique_models = dataset.model.unique()\n",
    "unique_scoring = dataset.scoring.unique()\n",
    "unique_datasets = dataset.dataset.unique()\n",
    "# unique_tuning = dataset.tuning.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd681a8b",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Extend the notebook from week 09 for the meta information. \n",
    "In this notebook I will use openml to perform tasks/flows in order to evaluate some encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892e803",
   "metadata": {},
   "source": [
    "- No tuning is used for all\n",
    "- Standard parameters used for all\n",
    "\n",
    "After some tests I found out, that one can only generate tests on active datasets. \n",
    "\n",
    "### Encoders\n",
    "\n",
    "https://contrib.scikit-learn.org/category_encoders/\n",
    "\n",
    "| Abbreviation | Name | From | Note |\n",
    "| :- | :- | :- | :- |\n",
    "| BE | Binary | category_encoders |  |\n",
    "| CBE | CatBoost | category_encoders |  |\n",
    "| CE | Count | category_encoders |  |\n",
    "| DE | Drop |  |  |\n",
    "| ME | Mean-Estimate | category_encoders | aka TargetEncoder: https://contrib.scikit-learn.org/category_encoders/targetencoder.html; also try M-Estimate as ME |\n",
    "| MHE | Min-Hash | skrub | https://skrub-data.org/stable/api.html |\n",
    "| OE | Ordinal | sklearn.preprocessing |  |\n",
    "| OHE | One-Hot | sklearn.preprocessing |  |\n",
    "| RGLMME | GLMM | category_encoders |  |\n",
    "| SE | Sum | category_encoders | Not sure im Sum coder or Summary Encoder |\n",
    "| TE | Mean-Target (not to be confused with Target) |  |  |\n",
    "| WOEE | Weight-of-Evidence | category_encoders |  |\n",
    "| BUCVX | BlowUp Cross-Validated X | ToDo: Implementation | Implemented by Federico |\n",
    "| CVX | Cross-Validated X |  |  |\n",
    "| DX | Discretized X | ToDo: Implementation | Implemented by Federico |\n",
    "| PBX | PreBinned X | ToDo: Implementation | Implemented by Federico |\n",
    "\n",
    "also use \n",
    "- HelemetEncoder from category_encoders\n",
    "- James-Stein may be another name for Mean-Target\n",
    "- Leave One out from category_encoders\n",
    "- ... and everything else, which comes to hand :)\n",
    "\n",
    "Links:\n",
    "- https://skrub-data.org/stable/install.html\n",
    "- https://contrib.scikit-learn.org/category_encoders/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35156b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import encoders\n",
    "from category_encoders import (\n",
    "    BackwardDifferenceEncoder, \n",
    "    BaseNEncoder, \n",
    "    BinaryEncoder, \n",
    "    CatBoostEncoder, \n",
    "    CountEncoder, \n",
    "    GLMMEncoder, \n",
    "    GrayEncoder, \n",
    "    HashingEncoder, \n",
    "    HelmertEncoder, \n",
    "    JamesSteinEncoder, \n",
    "    LeaveOneOutEncoder, \n",
    "    MEstimateEncoder, \n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder, \n",
    "    PolynomialEncoder, \n",
    "    QuantileEncoder, \n",
    "    RankHotEncoder, \n",
    "    SumEncoder, \n",
    "    SummaryEncoder, \n",
    "    TargetEncoder, \n",
    "    WOEEncoder\n",
    ")\n",
    "\n",
    "from skrub import (\n",
    "    GapEncoder, \n",
    "    MinHashEncoder, \n",
    "    SimilarityEncoder, \n",
    "    TargetEncoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "415f4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_encoders = {\n",
    "    \"BackwardDifferenceEncoder\": BackwardDifferenceEncoder(), \n",
    "    \"BaseNEncoder\"             : BaseNEncoder(), \n",
    "    \"BinaryEncoder\"            : BinaryEncoder(), \n",
    "    \"CatBoostEncoder\"          : CatBoostEncoder(), \n",
    "    \"CountEncoder\"             : CountEncoder(), \n",
    "    \"GLMMEncoder\"              : GLMMEncoder(), \n",
    "    \"GrayEncoder\"              : GrayEncoder(), \n",
    "    \"HashingEncoder\"           : HashingEncoder(), \n",
    "    \"HelmertEncoder\"           : HelmertEncoder(), \n",
    "    \"JamesSteinEncoder\"        : JamesSteinEncoder(), \n",
    "    \"LeaveOneOutEncoder\"       : LeaveOneOutEncoder(), \n",
    "    \"MEstimateEncoder\"         : MEstimateEncoder(), \n",
    "    \"OneHotEncoder\"            : OneHotEncoder(),\n",
    "    \"OrdinalEncoder\"           : OrdinalEncoder(), \n",
    "    \"PolynomialEncoder\"        : PolynomialEncoder(), \n",
    "    \"QuantileEncoder\"          : QuantileEncoder(), \n",
    "    \"RankHotEncoder\"           : RankHotEncoder(), \n",
    "    \"SumEncoder\"               : SumEncoder(), \n",
    "    \"SummaryEncoder\"           : SummaryEncoder(), \n",
    "    \"TargetEncoder\"            : TargetEncoder(), \n",
    "    \"WOEEncoder\"               : WOEEncoder(),\n",
    "    \n",
    "    \"GapEncoder\"               : GapEncoder(),  \n",
    "    \"MinHashEncoder\"           : MinHashEncoder(), \n",
    "    \"SimilarityEncoder\"        : SimilarityEncoder(), \n",
    "    \"TargetEncoder\"            : TargetEncoder()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ceb0b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BackwardDifferenceEncoder   ---   BackwardDifferenceEncoder()\n",
      "BaseNEncoder   ---   BaseNEncoder()\n",
      "BinaryEncoder   ---   BinaryEncoder()\n",
      "CatBoostEncoder   ---   CatBoostEncoder()\n",
      "CountEncoder   ---   CountEncoder(combine_min_nan_groups=True)\n",
      "GLMMEncoder   ---   GLMMEncoder()\n",
      "GrayEncoder   ---   GrayEncoder()\n",
      "HashingEncoder   ---   HashingEncoder(max_process=2)\n",
      "HelmertEncoder   ---   HelmertEncoder()\n",
      "JamesSteinEncoder   ---   JamesSteinEncoder()\n",
      "LeaveOneOutEncoder   ---   LeaveOneOutEncoder()\n",
      "MEstimateEncoder   ---   MEstimateEncoder()\n",
      "OneHotEncoder   ---   OneHotEncoder()\n",
      "OrdinalEncoder   ---   OrdinalEncoder()\n",
      "PolynomialEncoder   ---   PolynomialEncoder()\n",
      "QuantileEncoder   ---   QuantileEncoder()\n",
      "RankHotEncoder   ---   RankHotEncoder()\n",
      "SumEncoder   ---   SumEncoder()\n",
      "SummaryEncoder   ---   SummaryEncoder()\n",
      "TargetEncoder   ---   TargetEncoder()\n",
      "WOEEncoder   ---   WOEEncoder()\n",
      "GapEncoder   ---   GapEncoder()\n",
      "MinHashEncoder   ---   MinHashEncoder()\n",
      "SimilarityEncoder   ---   SimilarityEncoder()\n"
     ]
    }
   ],
   "source": [
    "for s, e in available_encoders.items():\n",
    "    print(f\"{s}   ---   {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e35bc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset_id = []\n",
    "list_model = []  # unique_models = ['DTC' 'KNC' 'LGBMC' 'LR' 'SVC']\n",
    "list_encoding = []\n",
    "list_scoring = []  # unique_scoring = ['ACC', 'AUC', 'F1']\n",
    "list_folds = []  # Will be constant in my case, may leave it \n",
    "list_cv_score = []  \n",
    "list_std_dev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5410c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "  DTC\n",
      "    BackwardDifferenceEncoder\n",
      "      ACC --- predictive_accuracy\n",
      "      AUC --- area_under_roc_curve\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:102\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/runs/functions.py:1019\u001b[0m, in \u001b[0;36mlist_runs\u001b[0;34m(offset, size, id, task, setup, flow, uploader, tag, study, display_errors, output_format, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m uploader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uploader, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muploader must be of type list.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_list_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlisting_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_list_runs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43msetup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43muploader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muploader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/utils.py:272\u001b[0m, in \u001b[0;36m_list_all\u001b[0;34m(listing_call, output_format, *args, **filters)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     current_offset \u001b[38;5;241m=\u001b[39m offset \u001b[38;5;241m+\u001b[39m BATCH_SIZE_ORIG \u001b[38;5;241m*\u001b[39m page\n\u001b[0;32m--> 272\u001b[0m     new_batch \u001b[38;5;241m=\u001b[39m \u001b[43mlisting_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mactive_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openml\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mOpenMLServerNoResult:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# we want to return an empty dict in this case\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/runs/functions.py:1106\u001b[0m, in \u001b[0;36m_list_runs\u001b[0;34m(id, task, setup, flow, uploader, study, display_errors, output_format, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_errors:\n\u001b[1;32m   1105\u001b[0m     api_call \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/show_errors/true\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__list_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/runs/functions.py:1111\u001b[0m, in \u001b[0;36m__list_runs\u001b[0;34m(api_call, output_format)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__list_runs\u001b[39m(api_call, output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to parse API calls which are lists of runs\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1111\u001b[0m     xml_string \u001b[38;5;241m=\u001b[39m \u001b[43mopenml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_calls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     runs_dict \u001b[38;5;241m=\u001b[39m xmltodict\u001b[38;5;241m.\u001b[39mparse(xml_string, force_list\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moml:run\u001b[39m\u001b[38;5;124m\"\u001b[39m,))\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# Minimalistic check if the XML is useful\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/_api_calls.py:93\u001b[0m, in \u001b[0;36m_perform_api_call\u001b[0;34m(call, request_method, data, file_elements)\u001b[0m\n\u001b[1;32m     91\u001b[0m     response \u001b[38;5;241m=\u001b[39m _read_url_files(url, data\u001b[38;5;241m=\u001b[39mdata, file_elements\u001b[38;5;241m=\u001b[39mfile_elements)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m__read_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m __check_response(response, url, file_elements)\n\u001b[1;32m     97\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.7f\u001b[39;00m\u001b[38;5;124ms taken for [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] request for the URL \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start,\n\u001b[1;32m    100\u001b[0m     request_method,\n\u001b[1;32m    101\u001b[0m     url,\n\u001b[1;32m    102\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/_api_calls.py:295\u001b[0m, in \u001b[0;36m__read_url\u001b[0;34m(url, request_method, data, md5_checksum)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mapikey:\n\u001b[1;32m    294\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mapikey\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5_checksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5_checksum\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/openml/_api_calls.py:318\u001b[0m, in \u001b[0;36m_send_request\u001b[0;34m(request_method, url, data, files, md5_checksum)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m request_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 318\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m request_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    320\u001b[0m         response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mdelete(url, params\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/requests/sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    599\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/urllib3/response.py:831\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m    833\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    834\u001b[0m )\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/site-packages/urllib3/response.py:784\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    782\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# amt > self.chunk_left\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/http/client.py:629\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    623\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1271\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/DS-Lab/lib/python3.10/ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "datasets_active_state = openml.datasets.check_datasets_active(unique_datasets)\n",
    "#eval_measures = ['predictive_accuracy', 'area_under_roc_curve', 'f_measure']\n",
    "evaluation_metrics = {\n",
    "    'ACC': 'predictive_accuracy',\n",
    "    'AUC': 'area_under_roc_curve',\n",
    "    'F1' : 'f_measure'\n",
    "}\n",
    "\n",
    "\n",
    "for dataset_id in unique_datasets:\n",
    "    print(dataset_id)\n",
    "    \n",
    "    if datasets_active_state[dataset_id]:\n",
    "        # Dataset is active\n",
    "        # Define the classifier and preprocessing steps\n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "        # ToDo: Implement the encoders and iterate over them\n",
    "        encoder = OneHotEncoder(categories='auto', sparse_output=False, handle_unknown='ignore')\n",
    "        encoder_string = \"OHE\"\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Iterate over models\n",
    "        for model_string in unique_models:\n",
    "            print(f\"  {model_string}\")\n",
    "            \n",
    "            # Choose classifier\n",
    "            if model_string == \"DTC\":\n",
    "                classifier = DecisionTreeClassifier()\n",
    "            elif model_string == \"KNC\":\n",
    "                classifier = KNeighborsClassifier()\n",
    "            elif model_string == \"LGBMC\":\n",
    "                classifier = LGBMClassifier()\n",
    "            elif model_string == \"LR\":\n",
    "                classifier = LinearRegression()\n",
    "            elif model_string == \"SVC\":\n",
    "                classifier = SVC()\n",
    "            else:\n",
    "                print(f\"Classifier '{model_string}' is not implemented!\")\n",
    "                continue\n",
    "            \n",
    "            # Iterate over available encoders\n",
    "            for encoder_string, encoder in available_encoders.items():\n",
    "                print(f\"    {encoder_string}\")\n",
    "                \n",
    "                # Set up the pipeline\n",
    "                pipeline = Pipeline(steps=[\n",
    "                    ('imputer', imputer),\n",
    "                    ('encoder', encoder),\n",
    "                    ('scaler', scaler),\n",
    "                    ('classifier', classifier)\n",
    "                ])\n",
    "\n",
    "                # Select task if it does not exist\n",
    "                existing_tasks = openml.tasks.list_tasks(\n",
    "                    task_type=openml.tasks.TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\"\n",
    "                )\n",
    "\n",
    "                for scoring in evaluation_metrics.keys():\n",
    "                    print(f\"      {scoring} --- {evaluation_metrics[scoring]}\")\n",
    "\n",
    "                    # Prepare filter\n",
    "                    task_filter = ((existing_tasks['did'] == dataset_id) & (existing_tasks['estimation_procedure'] == '10-fold Crossvalidation') & ((existing_tasks['evaluation_measures'].isna()) | (existing_tasks['evaluation_measures'] == evaluation_metrics[scoring])))\n",
    "                    #filtered_tasks = tasks[task_filter]\n",
    "\n",
    "                    # Check if task exists\n",
    "                    if existing_tasks[task_filter].shape[0] > 0:\n",
    "                        # task exists\n",
    "\n",
    "                        task = openml.tasks.get_task(task_id=existing_tasks[task_filter].iloc[0].tid)\n",
    "                    else:\n",
    "                        # Create a new task and publish it\n",
    "                        print(\"Create task\")\n",
    "                        new_task = openml.tasks.create_task(task_type=openml.tasks.TaskType.SUPERVISED_CLASSIFICATION,\n",
    "                                                        dataset_id=3,\n",
    "                                                        target_name=\"class\",\n",
    "                                                        evaluation_measure=\"f_measure\",\n",
    "                                                        estimation_procedure_id=1   # '10-fold Crossvalidation',\n",
    "                        )\n",
    "                        new_task.publish()\n",
    "\n",
    "                        # Now list tasks again and select the new task\n",
    "                        existing_tasks = openml.tasks.list_tasks(\n",
    "                            task_type=openml.tasks.TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\"\n",
    "                        )\n",
    "                        task = openml.tasks.get_task(task_id=existing_tasks[task_filter].iloc[0].tid)\n",
    "\n",
    "                    # Check if the run has already be performed, if yes load it    \n",
    "                    list_runs = openml.runs.list_runs(task=[task.id])\n",
    "                    list_runs_values = list(list_runs.values())\n",
    "                    if len(list_runs_values) == 0:\n",
    "                        # Run the task\n",
    "                        run = openml.runs.run_model_on_task(model=pipeline, task=task, seed=42)\n",
    "                        run.publish()\n",
    "                        run_id = run.id\n",
    "\n",
    "                    else:\n",
    "                        # Get the task which has already be run\n",
    "                        run_id = list_runs_values[0]['run_id']\n",
    "\n",
    "                    # Run the model on the task\n",
    "                    run_result = openml.runs.get_run(run_id)\n",
    "\n",
    "                    # For some reason sometimes the results are contained in the run object and sometimes not\n",
    "                    if run_result.fold_evaluations is not None:\n",
    "                        # Calculate results to get cv_score and std dev\n",
    "                        cv_score = np.mean(list(run_result.fold_evaluations[evaluation_metrics[scoring]][0].values()))\n",
    "                        std_dev = np.std(list(run_result.fold_evaluations[evaluation_metrics[scoring]][0].values()))\n",
    "                    else:\n",
    "                        # Maybe needs to sleep for short after publishing the run\n",
    "                        time.sleep(3)\n",
    "\n",
    "                        # Get evaluations\n",
    "                        list_evaluations = openml.evaluations.list_evaluations(function=evaluation_metrics[scoring], runs=[run_id])\n",
    "                        eval_result = list(list_evaluations.values())[0]\n",
    "                        cv_score = eval_result.value\n",
    "                        std_dev = math.nan\n",
    "\n",
    "                    # Append results to list\n",
    "                    list_dataset_id.append(dataset_id)\n",
    "                    list_model.append(model_string)\n",
    "                    list_encoding.append(encoder_string)\n",
    "                    list_scoring.append(scoring)\n",
    "                    list_folds.append(10)\n",
    "                    list_cv_score.append(cv_score)\n",
    "                    list_std_dev.append(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_data = {}\n",
    "\n",
    "evaluations_data['dataset_id'] = list_dataset_id\n",
    "evaluations_data['model'] = list_model\n",
    "evaluations_data['encoding'] = list_encoding\n",
    "evaluations_data['scoring'] = list_scoring\n",
    "evaluations_data['folds'] = list_folds\n",
    "evaluations_data['cv_score'] = list_cv_score\n",
    "evaluations_data['std_dev'] = list_std_dev\n",
    "\n",
    "evaluations = pd.DataFrame(data=evaluations_data)\n",
    "\n",
    "evaluations.to_csv('../../data/preprocessed/evaluations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3be995",
   "metadata": {},
   "source": [
    "## How to integrate the data in the pipeline?\n",
    "\n",
    "Add all encoder evaluations as features to the data. \n",
    "Add one column 'suggested_score' where I try to map the calculated cv_scores according to the columns ```[model, encoder, scoring, dataset]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ba45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to abbreviaton\n",
    "mapping_of_encoder_abbreviations = {\n",
    "    \"BackwardDifferenceEncoder\": \"\", \n",
    "    \"BaseNEncoder\"             : \"\", \n",
    "    \"BinaryEncoder\"            : \"BE\",      # Given by Federico\n",
    "    \"CatBoostEncoder\"          : \"CBE\",     # Given by Federico\n",
    "    \"CountEncoder\"             : \"CE\",      # Given by Federico\n",
    "    \"GLMMEncoder\"              : \"RGLMME\",  # Given by Federico\n",
    "    \"GrayEncoder\"              : \"\", \n",
    "    \"HashingEncoder\"           : \"\", \n",
    "    \"HelmertEncoder\"           : \"\", \n",
    "    \"JamesSteinEncoder\"        : \"\", \n",
    "    \"LeaveOneOutEncoder\"       : \"\", \n",
    "    \"MEstimateEncoder\"         : \"\", \n",
    "    \"OneHotEncoder\"            : \"OHE\",     # Given by Federico\n",
    "    \"OrdinalEncoder\"           : \"OE\",      # Given by Federico\n",
    "    \"PolynomialEncoder\"        : \"\", \n",
    "    \"QuantileEncoder\"          : \"\", \n",
    "    \"RankHotEncoder\"           : \"\", \n",
    "    \"SumEncoder\"               : \"SE\",      # Given by Federico\n",
    "    \"SummaryEncoder\"           : \"\", \n",
    "    \"TargetEncoder\"            : \"\", \n",
    "    \"WOEEncoder\"               : \"WOEE\",\n",
    "    \n",
    "    \"GapEncoder\"               : \"\",  \n",
    "    \"MinHashEncoder\"           : \"MHE\",     # Given by Federico \n",
    "    \"SimilarityEncoder\"        : \"\", \n",
    "    \"TargetEncoder\"            : \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations between all calculated cv_scores for all encoders with actual target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
